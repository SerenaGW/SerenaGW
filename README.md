
## Hi, I'm Serena 👋

I'm an AI security researcher, focusing on cutting-edge vulnerabilities that challenge the internal logic of language models.

<img width="800" height="800" alt="image" src="https://github.com/user-attachments/assets/e432a796-b6b8-48a3-b77c-1869d8a0bcd6" />
---

### My Mission! ⭐️
I work on the frontiers of red teaming, discovering and documenting vulnerabilities to help build a safer and more responsible AI ecosystem. My goal is to ensure that defenses advance faster than attacks.

---

### 🛠️ Projects and Contributions
* **The Future of AI Safety: How Symbolic Language Reveals Paths Towards LLM Resilience:** https://github.com/SerenaGW/LLMReadteamSymbolic
* **Semantic Re-signification and Linguistic Denial of Service in LLMs:** https://github.com/SerenaGW/LLMReadTeamLinguisticDoS/tree/main
* **Symbolic Language Fine-Tuning Guide:** Coming soon—a free guide that reveals advanced techniques for fine-tuning LLMs, with a focus on how their vulnerabilities can be exploited and mitigated.

---

### 📧 Contact
https://www.linkedin.com/in/serena-gomez-wannaz/
